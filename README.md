# uncrater
LuSEE Night binary blob unpackager

## Dependencies
To install Python dependencies, run
```bash
pip install -r requirements.txt
```
Install latex
```bash
sudo apt install texlive-latex-base
sudo apt-get install texlive-latex-extra
```

## Coreloop dependency

The python module `pycoreloop` that contains definitions of AppIDs and Spectrometer commands has to be imported.
You can specify `CORELOOP_DIR` to specify the directory of the [coreloop](https://github.com/lusee-night/coreloop/) branch.
In most setups `export CORELOOP_DIR=..` will do the job.

## Testing suite

Test are accessed using the CLI interface in `test/cli_driver.py`. Running 
```
python test/cli_driver.py --help
```
will list the available options.

Useful options:
 * `-l` will list available tests
 * `-i test_name` will show more information about the test and its options
 * `-r test_name` will perform the test, analyze and produce a pdf report. The report (together with more data) can be found, by default, in `session_test_name/report.pdf`
 * `-a test_name` will run just the analysis and report producing part (useful, for example, when debugging the actual analysis.)


 ### Developing and debugging the test suite

 
Before we go into tests, let's briefly discuss the mechanics of how these commands and response are constructed.

Spectrometer commands have 1 byte command and 2 byte argument. The high level command fall all under the `RFS_SETTINGS` (0x10) command. This is majorly so that our high level commanding ICD is fixed.
In this case we use the upper 8 bits of the two bytes as the sub-commands, or more colloquialy in the coreloop context as spectrometer command and one byte as an argument. This is a very compressed representation. The *reference place for command definitions* is under the coreloop repo in [`documentation/lusee_commands.md`](https://github.com/lusee-night/coreloop/blob/devel/documentation/lusee_commands.md). Definitions changes should always happen in that table. Then cmake is executed in the coreloop directory, and old school make is executed in `pycoreloop` in that directory which generates the appropriate `lusee_commands.py` and `lusee_commands.h`. `lusee_commands.py` is imported in the `pycoreloop` library. This library is imported into the high-level scription model [`lusee_script.py`](scripter/lusee_script.py). `lusee_script.py` abstracts away the cumbersome two-byte commanding into something that is human readable. By for exampling calling `set_anagain('MMMM')` the command to set the analog gain to medium in all 4 analog channels. This refers to `lusee_commands.RFS_SET_GAIN_ANA_SET` which in turns ultimately picks up the actual subcommand number from the markdown table in the documentation. 

The data generated by the spectrometer are return in packets which (under the all the CCSDS cruft) are defined by a binary blob and an appID. AppId is an identifier that tells you what kind of information is in the binary blob. This allows you to interpret that packet correclty. It very important to realize, that the architecture is not command - response one. We cannot afford to do any interfactive commanding on the moon and the DCB will at program the spectrometer and then keep it hads away.  Yes, there are packets to e.g. request a housekeeping of a certain type but all this implies that there will be a housekeeping packet sent sometime soon. For example, if the spectrometer is in the middle of sending spectrometer data, there could be two more data packets and a hearbeat packet comming between the housekeeping command being issued and housekeeping packet being received. The spectrometer is assigned AppIds 0x2XX. Similarly to commands, the AppIDs are defined in mark down table in the coreloop packages [`documentation/lusee_appIDs.md`](https://github.com/lusee-night/coreloop/blob/devel/documentation/lusee_appIds.md) and similarly `lusee_appIds.h` and `lusee_appIds.py` are auto-generated from that reference markdown package. The actual contents for a given appID is defined by `coreloop.h` mostly as packed C-structures, although for some data one actually needs to dig into the code to understand how it fits together. On the python side, these packets are interpreted using the `uncrater` module. `uncrater` module uses pycoreloop for two things. First, it uses `pycoreloop.appId` and associated dictionaries to link appIDd descritpions with their numerical values. Second, it uses `pycore.pystruct` to import the C-structures that are in these packages. `pycore.pystrcuct` is again programmatically generated from `coreloop/core_loop.h` using [ctypesgen](https://github.com/ctypesgen/ctypesgen) to generate python wrapper for coreloops's C structures. For example, look at [`PacketHello.py`](uncrater/Packet_Hello.py): it takes binary blob, interprets it as `startup_hello` structure and copies all attributes over. The `startup_hello` structure is ultimatelyu defined in [`core_loop.h`](https://github.com/lusee-night/coreloop/blob/devel-2/coreloop/core_loop.h) line 134 at the time of writing. If it gets changed there, the cmake will update the pycoreloop and these changes will transparently propagate into uncrater. The uncrater has an object `Collection` which can deal with a collection of packets and interpret them as needed.

So now we have the tools to generate commands and understand responses. Next we need to use those to make a test.  Each test is composed of these steps:
  * Preparing a list of commands
  * Sending that list of commands, together with appropriate wait states to a hardware of coreloop running on a PC
  * Collecting the output of the spectrometer during the test period
  * Analyzing the output of the spectrometer
  * Writing a report

This structure is imposed into the base class object [`test/test_base.py`](test/test_base.py). Each test corresponds to a derived object that inherits from `Test` object (defined in `test_base.py`). The command line drive in `test/cli_driver.py` can therefore execute any test in an automated fashion. We can get the list of available options with 

```
$ python test/cli_driver.py --help

usage: cli_driver.py [-h] [-l] [-i] [-r] [-a] [-o OPTIONS] [-w WORKDIR] [-v] [-b BACKEND] [--operator OPERATOR] [--comments COMMENTS] [test_name]

Driver for tests.

positional arguments:
  test_name             Name of the test

options:
  -h, --help            show this help message and exit
  -l, --list            Show the available tests
  -i, --info            Print information for the test
  -r, --run             Run the test and analyze the results
  -a, --analyze         Analyze the results on a previously run test
  -o OPTIONS, --options OPTIONS
                        Test options, option=value, comma or space separated.
  -w WORKDIR, --workdir WORKDIR
                        Output directory (as test_name.pdf)
  -v, --verbose         Verbose processing
  -b BACKEND, --backend BACKEND
                        What to command. Possible values: DCBEmu (DCB Emulator), DCB (DCB), coreloop (coreloop running on PC)
  --operator OPERATOR   Operator name (for the report)
  --comments COMMENTS   Comments(for the report)
```


 This is illustrated in the aliveness test [`test/test_alive.py`](test/test_alive.py). The concepts described here are illustrated below.

In particular, test needs to define the following class variables with obvious names:

  * `name`
  * `description` - short description
  * `instructions` - instructions for how to execute the test if any special setup is needed
  * `default_options` - dictionary with default options 
  * `options_help` - dictionary mapping option names to descriptions

If a test is added to the `cli_driver.py` list of availabe tests it should be automatically executable.

#### Preparing the list of commamnds.

The list of commands is prepared using the scripter in the `generate_script` method taking into account the options. Options are copied straight into object's attribute.

#### Analyzing the output

The output is analyzed in the `analyze` method. This mehtod received, among other things a `Collection` of packets. If performs its analysis based on packets in that collection and saves results in the `self.results` dictionary.

#### Writing report

Report is finally assembled from pieces of latex saved in `test/report_templates` as follows:
 * `header.tex`, `body_testname.tex` and `footer.tex` are collated in the report
 * For every key in results dictionary, `++key++` is replaced with the contents of that key
 * The report is saved in the working directory and pdflatex is executed


 #### Mechanics of executing the test

 This part is subject to change and the current solution is there only temporarily. The script that is generated by `generate_script` command is passed to the `Commander`. `Commander` can speak to several back-ends, in principle, currenlty just to the `DCBemu` (DCB emulator). It sends commands (and processes occasional wait states) via UDP to DCB Emulator in one thread and collects the packets in the other thread. The packets are saved into a `working_dir/cdi_results` in a one file per packet format. The CLI driver collects these packest though the `Collection` object and passes it forward.
  


